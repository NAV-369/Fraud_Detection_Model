{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Example model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = fraud_data_df.drop(columns=[\"class\"])  # Drop the target column\n",
    "y = fraud_data_df[\"class\"]  # Use \"class\" as the target variable\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"random_forest_fraud.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the Model with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values shape: 1000\n",
      "Shape of X_test_small: (1000, 10)\n",
      "First few shap_values_subset[1]: [[ 0.0023271  -0.0023271 ]\n",
      " [ 0.01557039 -0.01557039]\n",
      " [ 0.02070202 -0.02070202]\n",
      " [ 0.00457055 -0.00457055]\n",
      " [ 0.00364243 -0.00364243]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The shape of the shap_values matrix does not match the shape of the provided data matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 58\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst few shap_values_subset[1]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshap_values_subset[\u001b[38;5;241m1\u001b[39m][:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Plot the SHAP summary for class 1 (assuming fraud is class 1)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Ensure that shap_values_subset[1] aligns with X_test_small\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshap_values_subset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_small\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Alternatively, if there is an additional column (base value), remove it\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# shap.summary_plot(shap_values_subset[1][:, :-1], X_test_small)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Save SHAP values\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshap_values.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/envs/shared_env/lib/python3.9/site-packages/shap/plots/_beeswarm.py:543\u001b[0m, in \u001b[0;36msummary_legacy\u001b[0;34m(shap_values, features, feature_names, max_display, plot_type, color, axis_color, title, alpha, show, sort, color_bar, plot_size, layered_violin_max_num_bins, class_names, class_inds, color_bar_label, cmap, show_values_in_legend, use_log_scale)\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, shape_msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Perhaps the extra column in the shap_values matrix is the \u001b[39m\u001b[38;5;124m\"\u001b[39m \\\n\u001b[1;32m    541\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant offset? Of so just pass shap_values[:,:-1].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 543\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m num_features \u001b[38;5;241m==\u001b[39m features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], shape_msg\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    546\u001b[0m     feature_names \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([labels[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEATURE\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_features)])\n",
      "\u001b[0;31mAssertionError\u001b[0m: The shape of the shap_values matrix does not match the shape of the provided data matrix."
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "fraud_data_df = pd.read_csv('../data/Fraud_Data.csv')\n",
    "\n",
    "# Convert datetime columns to numeric (if any)\n",
    "if 'datetime_column' in fraud_data_df.columns:  # Replace with the actual column name\n",
    "    fraud_data_df['datetime_column'] = pd.to_datetime(fraud_data_df['datetime_column'])\n",
    "    fraud_data_df['year'] = fraud_data_df['datetime_column'].dt.year\n",
    "    fraud_data_df['month'] = fraud_data_df['datetime_column'].dt.month\n",
    "    fraud_data_df['day'] = fraud_data_df['datetime_column'].dt.day\n",
    "    fraud_data_df['hour'] = fraud_data_df['datetime_column'].dt.hour\n",
    "    fraud_data_df['minute'] = fraud_data_df['datetime_column'].dt.minute\n",
    "    fraud_data_df.drop(columns=['datetime_column'], inplace=True)  # Remove original column\n",
    "\n",
    "# Handle categorical columns by encoding them (if any)\n",
    "categorical_columns = fraud_data_df.select_dtypes(include=['object']).columns\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    fraud_data_df[col] = encoder.fit_transform(fraud_data_df[col])\n",
    "\n",
    "# Split into features and target\n",
    "X = fraud_data_df.drop(columns=[\"class\"])  # Replace \"class\" with the actual target column name\n",
    "y = fraud_data_df[\"class\"]  # Replace \"class\" with the actual target column name\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the RandomForest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# For testing, you can sample a smaller portion of your dataset\n",
    "X_test_small = X_test.sample(n=1000, random_state=42)\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values_subset = explainer.shap_values(X_test_small)\n",
    "\n",
    "# Check the shape of SHAP values to ensure the index corresponds to the right class\n",
    "print(f\"SHAP values shape: {len(shap_values_subset)}\")\n",
    "\n",
    "# Check the shape of X_test_small for consistency\n",
    "print(f\"Shape of X_test_small: {X_test_small.shape}\")\n",
    "\n",
    "# Print the first few entries of shap_values_subset to inspect them\n",
    "print(f\"First few shap_values_subset[1]: {shap_values_subset[1][:5]}\")\n",
    "\n",
    "# Plot the SHAP summary for class 1 (assuming fraud is class 1)\n",
    "# Ensure that shap_values_subset[1] aligns with X_test_small\n",
    "shap.summary_plot(shap_values_subset[1], X_test_small)\n",
    "\n",
    "# Alternatively, if there is an additional column (base value), remove it\n",
    "# shap.summary_plot(shap_values_subset[1][:, :-1], X_test_small)\n",
    "\n",
    "# Save SHAP values\n",
    "with open(\"shap_values.pkl\", \"wb\") as f:\n",
    "    pickle.dump(shap_values_subset, f)\n",
    "\n",
    "print(\"SHAP values and plot created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate SHAP Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary Plot (Overall Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[1], X_test)  # Assuming fraud is class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Force Plot (Single Prediction Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single instance\n",
    "i = 10  # Change the index to analyze different instances\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][i], X_test.iloc[i], matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependence Plot (Feature-Target Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"amount\", shap_values[1], X_test)  # Replace \"amount\" with a key feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the Model with LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize LIME Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values, feature_names=X.columns, class_names=[\"Not Fraud\", \"Fraud\"], mode=\"classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate LIME Explanation for a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10  # Change index to explain different predictions\n",
    "exp = explainer.explain_instance(X_test.iloc[i].values, model.predict_proba)\n",
    "\n",
    "# Show LIME explanation\n",
    "exp.show_in_notebook()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
