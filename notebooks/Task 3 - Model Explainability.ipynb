{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier  # Example model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = fraud_data_df.drop(columns=[\"class\"])  # Drop the target column\n",
    "y = fraud_data_df[\"class\"]  # Use \"class\" as the target variable\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the trained model\n",
    "model = joblib.load(\"random_forest_fraud.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the Model with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values shape: 1000\n",
      "Shape of X_test_small: (1000, 10)\n",
      "SHAP values subset type: <class 'numpy.ndarray'>\n",
      "SHAP values for class 1 structure: (10, 2)\n",
      "SHAP values for class 1 (first few rows): [[ 0.0023271  -0.0023271 ]\n",
      " [ 0.01557039 -0.01557039]\n",
      " [ 0.02070202 -0.02070202]\n",
      " [ 0.00457055 -0.00457055]\n",
      " [ 0.00364243 -0.00364243]]\n",
      "Shape mismatch: SHAP values shape (10, 2) does not match X_test_small shape (1000, 10)\n",
      "SHAP values and plot created successfully!\n"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Load the dataset\n",
    "fraud_data_df = pd.read_csv('../data/Fraud_Data.csv')\n",
    "\n",
    "# Convert datetime columns to numeric (if any)\n",
    "if 'datetime_column' in fraud_data_df.columns:  # Replace with the actual column name\n",
    "    fraud_data_df['datetime_column'] = pd.to_datetime(fraud_data_df['datetime_column'])\n",
    "    fraud_data_df['year'] = fraud_data_df['datetime_column'].dt.year\n",
    "    fraud_data_df['month'] = fraud_data_df['datetime_column'].dt.month\n",
    "    fraud_data_df['day'] = fraud_data_df['datetime_column'].dt.day\n",
    "    fraud_data_df['hour'] = fraud_data_df['datetime_column'].dt.hour\n",
    "    fraud_data_df['minute'] = fraud_data_df['datetime_column'].dt.minute\n",
    "    fraud_data_df.drop(columns=['datetime_column'], inplace=True)  # Remove original column\n",
    "\n",
    "# Handle categorical columns by encoding them (if any)\n",
    "categorical_columns = fraud_data_df.select_dtypes(include=['object']).columns\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    fraud_data_df[col] = encoder.fit_transform(fraud_data_df[col])\n",
    "\n",
    "# Split into features and target\n",
    "X = fraud_data_df.drop(columns=[\"class\"])  # Replace \"class\" with the actual target column name\n",
    "y = fraud_data_df[\"class\"]  # Replace \"class\" with the actual target column name\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the RandomForest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# For testing, you can sample a smaller portion of your dataset\n",
    "X_test_small = X_test.sample(n=1000, random_state=42)\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values_subset = explainer.shap_values(X_test_small)\n",
    "\n",
    "# Check the shape of SHAP values to ensure the index corresponds to the right class\n",
    "print(f\"SHAP values shape: {len(shap_values_subset)}\")\n",
    "\n",
    "# Check the shape of X_test_small for consistency\n",
    "print(f\"Shape of X_test_small: {X_test_small.shape}\")\n",
    "\n",
    "# Check if SHAP values are a list or numpy array\n",
    "print(f\"SHAP values subset type: {type(shap_values_subset)}\")\n",
    "\n",
    "# Check the structure of SHAP values for class 1 (fraud)\n",
    "print(f\"SHAP values for class 1 structure: {shap_values_subset[1].shape}\")\n",
    "\n",
    "# Check if we have extra columns (such as base values)\n",
    "print(f\"SHAP values for class 1 (first few rows): {shap_values_subset[1][:5]}\")\n",
    "\n",
    "# Ensure SHAP values align with feature matrix X_test_small\n",
    "if shap_values_subset[1].shape[0] == X_test_small.shape[0]:\n",
    "    # Plot the SHAP summary for class 1 (assuming fraud is class 1)\n",
    "    shap.summary_plot(shap_values_subset[1], X_test_small)\n",
    "else:\n",
    "    print(f\"Shape mismatch: SHAP values shape {shap_values_subset[1].shape} does not match X_test_small shape {X_test_small.shape}\")\n",
    "\n",
    "# Save SHAP values\n",
    "with open(\"shap_values.pkl\", \"wb\") as f:\n",
    "    pickle.dump(shap_values_subset, f)\n",
    "\n",
    "print(\"SHAP values and plot created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate SHAP Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Summary Plot (Overall Feature Importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import shap\n",
    "\n",
    "# Assuming you have a trained model, for example, 'model' and a test set 'X_test'\n",
    "explainer = shap.TreeExplainer(model)  # For tree-based models like XGBoost\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Now, you can create the summary plot\n",
    "shap.summary_plot(shap_values[1], X_test)  # Assuming fraud is class 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Force Plot (Single Prediction Explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single instance\n",
    "i = 10  # Change the index to analyze different instances\n",
    "shap.force_plot(explainer.expected_value[1], shap_values[1][i], X_test.iloc[i], matplotlib=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependence Plot (Feature-Target Relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"amount\", shap_values[1], X_test)  # Replace \"amount\" with a key feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the Model with LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize LIME Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    X_train.values, feature_names=X.columns, class_names=[\"Not Fraud\", \"Fraud\"], mode=\"classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate LIME Explanation for a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10  # Change index to explain different predictions\n",
    "exp = explainer.explain_instance(X_test.iloc[i].values, model.predict_proba)\n",
    "\n",
    "# Show LIME explanation\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
